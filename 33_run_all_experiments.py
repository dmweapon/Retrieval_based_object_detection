# pip install numpy qdrant-client scikit-learn tqdm

import os
import csv
import sys
import uuid
import datetime
import numpy as np
from pathlib import Path
from collections import defaultdict
from tqdm import tqdm
from qdrant_client import QdrantClient
from qdrant_client.models import Filter, FieldCondition, MatchValue
from sklearn.metrics import accuracy_score

# -------------------- í•˜ì´í¼íŒŒë¼ë¯¸í„° --------------------

# ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°
root_dir = input("ë°ì´í„° ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: dataset_segmented): ").strip()
original_image_dir = "original_images"
natural_image_dir = "natural_images"

# Qdrant ì„¤ì •
qdrant_host = input("Qdrant í˜¸ìŠ¤íŠ¸ [ê¸°ë³¸ê°’: localhost]: ").strip() or "localhost"
qdrant_port = input("Qdrant í¬íŠ¸ [ê¸°ë³¸ê°’: 6333]: ").strip()
qdrant_port = int(qdrant_port) if qdrant_port else 6333

# ì‹¤í—˜ ì„¤ì •
cases = ['case_a', 'case_b', 'case_c']
delegate_types = ['average', 'centroid', 'weighted', 'medoid']

# -------------------- ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ --------------------

def get_output_csv_path():
    today = datetime.datetime.now().strftime("%Y-%m-%d")
    count = 1
    base_dir = Path("results")
    while True:
        subdir = base_dir / f"{today}-{count}"
        file_path = subdir / f"result_{today}-{count}.csv"
        if not file_path.exists():
            subdir.mkdir(parents=True, exist_ok=True)
            return file_path
        count += 1

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# -------------------- Qdrant Client ì´ˆê¸°í™” --------------------

client = QdrantClient(host=qdrant_host, port=qdrant_port)
collections = [c.name for c in client.get_collections().collections]

# natural ì´ë¯¸ì§€ì— ëŒ€í•œ í†µê³„ ì €ì¥ìš©
class_image_count = defaultdict(int)

# -------------------- ì‹¤í—˜ ìˆ˜í–‰ --------------------

all_results = []

print("\nì‹¤í—˜ì„ ì‹œì‘í•©ë‹ˆë‹¤. ì´ 12ê°œì˜ ì‹¤í—˜ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.\n")

for case in cases:
    collection_name = f"clip_embedding_{case}"
    if collection_name not in collections:
        print(f"\u274C {collection_name} ì»¬ë ‰ì…˜ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìŠ¤í‚µí•©ë‹ˆë‹¤.")
        continue

    # natural ì´ë¯¸ì§€ ë£¨í”„
    for class_name in sorted(os.listdir(f"{root_dir}/{natural_image_dir}")):
        class_dir = Path(root_dir) / natural_image_dir / class_name
        if not class_dir.is_dir():
            continue

        for img_file in tqdm(list(class_dir.glob("*.png")), desc=f"{case}/{class_name}"):
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì„ë² ë”© ë²¡í„° ë¶ˆëŸ¬ì˜¤ê¸°
            scroll_result, _ = client.scroll(
                collection_name=collection_name,
                scroll_filter=Filter(
                    must=[
                        FieldCondition(key="img_path", match=MatchValue(value=str(img_file))),
                        FieldCondition(key="is_delegate", match=MatchValue(value=False))
                    ]
                ),
                with_vectors=True,
                with_payload=True
            )
            if not scroll_result:
                continue

            test_vec = np.array(scroll_result[0].vector)
            class_image_count[class_name] += 1

            # ê° ëŒ€í‘œ ë²¡í„° íƒ€ì…ë³„ ìœ ì‚¬ë„ ë¹„êµ
            for dtype in delegate_types:
                scroll_delegate, _ = client.scroll(
                    collection_name=collection_name,
                    scroll_filter=Filter(
                        must=[
                            FieldCondition(key="delegate_type", match=MatchValue(value=dtype)),
                            FieldCondition(key="is_delegate", match=MatchValue(value=True))
                        ]
                    ),
                    with_vectors=True,
                    with_payload=True,
                    limit=9999
                )

                best_score = -1
                best_class = None

                for p in scroll_delegate:
                    ref_vec = np.array(p.vector)
                    score = cosine_similarity(test_vec, ref_vec)
                    if score > best_score:
                        best_score = score
                        best_class = p.payload.get("class_name")

                all_results.append({
                    "experiment_id": f"{case}_{dtype}",
                    "case": case,
                    "delegate_type": dtype,
                    "image_path": str(img_file),
                    "true_class": class_name,
                    "predicted_class": best_class,
                    "similarity_score": best_score
                })

# -------------------- CSV ì €ì¥ --------------------

output_path = get_output_csv_path()

with open(output_path, 'w', newline='') as f:
    writer = csv.DictWriter(f, fieldnames=[
        "experiment_id", "case", "delegate_type", "image_path",
        "true_class", "predicted_class", "similarity_score"])
    writer.writeheader()
    writer.writerows(all_results)

print(f"\nâœ… ì‹¤í—˜ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")

# -------------------- ìš”ì•½ í†µê³„ ì¶œë ¥ --------------------

print("\nğŸ“Š natural ì´ë¯¸ì§€ ì‚¬ìš© í†µê³„:")
print("í´ë˜ìŠ¤ ìˆ˜:", len(class_image_count))
for cname, count in sorted(class_image_count.items()):
    print(f" - {cname}: {count}ì¥")